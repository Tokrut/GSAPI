# [file name]: analyzer/deep_llm_analyzer.py
"""
–ì–ª—É–±–æ–∫–∏–π LLM-–∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –¥–ª—è GEO —Å –ø–æ–∏—Å–∫–æ–º –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤
–†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è —Å —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–º –∞–Ω–∞–ª–∏–∑–æ–º –∞–Ω–∞–ª–æ–≥–∏—á–Ω—ã—Ö —Å–∞–π—Ç–æ–≤ –∏ –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–º–∏ –∏—Ç–æ–≥–∞–º–∏
"""

import json
import re
import time
import logging
from typing import Dict, List, Any, Optional, Tuple
import pandas as pd
from datetime import datetime
from analyzer.llm_analyzer import LLMAnalyzer
from config import ANALYSIS_CONFIG

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logger = logging.getLogger(__name__)


class DeepLLMAnalyzer(LLMAnalyzer):
    """–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Å –ø–æ–∏—Å–∫–æ–º –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤ –∏ –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–º —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–º –∞–Ω–∞–ª–∏–∑–æ–º"""
    
    def __init__(self):
        super().__init__()
        self.competitor_cache = {}
        self.comparative_analysis_cache = {}
    
    def deep_analyze_with_competitors(self, target_url: str, max_competitors: int = 5) -> Dict[str, Any]:
        """
        –ì–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Å–∞–π—Ç–∞ —Å –ø–æ–∏—Å–∫–æ–º –∏ –æ—Ü–µ–Ω–∫–æ–π –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤
        
        Args:
            target_url: URL —Ü–µ–ª–µ–≤–æ–≥–æ —Å–∞–π—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            max_competitors: –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —Å –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–º–∏ –∏—Ç–æ–≥–∞–º–∏
        """
        try:
            logger.info(f"üöÄ –ù–∞—á–∏–Ω–∞–µ–º –≥–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ –¥–ª—è: {target_url}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
            cache_key = f"{target_url}_{max_competitors}"
            if cache_key in self.comparative_analysis_cache:
                logger.info("üìÅ –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞")
                return self.comparative_analysis_cache[cache_key]
            
            # –®–∞–≥ 1: –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤ —á–µ—Ä–µ–∑ DeepSeek
            logger.info("üîç –ü–æ–∏—Å–∫ –∞–Ω–∞–ª–æ–≥–∏—á–Ω—ã—Ö —Å–∞–π—Ç–æ–≤...")
            competitors = self._find_competitors_with_deepseek(target_url, max_competitors)
            
            # –®–∞–≥ 2: –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ URL –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            all_urls = [target_url] + competitors
            logger.info(f"üìä –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º {len(all_urls)} —Å–∞–π—Ç–æ–≤: {all_urls}")
            
            # –®–∞–≥ 3: –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π URL
            analysis_results = {}
            for url in all_urls:
                logger.info(f"üîÑ –ê–Ω–∞–ª–∏–∑ {url}...")
                content_data = self._fetch_content_data(url)
                if content_data:
                    analysis_results[url] = self.analyze_content_for_geo(content_data)
                    time.sleep(2)  # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                else:
                    logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è {url}")
                    analysis_results[url] = self._get_fallback_analysis({})
            
            # –®–∞–≥ 4: –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–º–∏ –∏—Ç–æ–≥–∞–º–∏
            logger.info("üìà –í—ã–ø–æ–ª–Ω—è–µ–º –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑...")
            comparative_analysis = self._perform_comprehensive_comparative_analysis(
                analysis_results, target_url, competitors
            )
            
            # –®–∞–≥ 5: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏—Ç–æ–≥–æ–≤–æ–≥–æ –æ—Ç—á–µ—Ç–∞
            logger.info("üìã –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç...")
            comparative_analysis['comprehensive_summary'] = self._generate_comprehensive_summary(
                comparative_analysis
            )
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à
            self.comparative_analysis_cache[cache_key] = comparative_analysis
            
            return comparative_analysis
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –≥–ª—É–±–æ–∫–æ–º –∞–Ω–∞–ª–∏–∑–µ: {str(e)}")
            return self._get_deep_fallback_analysis(target_url, str(e))
    
    def _perform_comprehensive_comparative_analysis(self, analysis_results: Dict[str, Any], 
                                              target_url: str, competitors: List[str]) -> Dict[str, Any]:
        """–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è–º–∏ –¥–æ—Å—Ç—É–ø–∞ –∫ –ø–æ–∑–∏—Ü–∏—è–º"""
        comparative = {
            'target_url': target_url,
            'competitors_list': competitors,
            'competitors_analyzed': len(competitors),
            'total_sites_analyzed': len(analysis_results),
            'analysis_timestamp': datetime.now().isoformat(),
            'ranking': [],
            'competitive_analysis': {},
            'strengths_weaknesses': {},
            'strategic_recommendations': [],
            'performance_metrics': {},
            'market_position_analysis': {},
            'improvement_potential': {},
            'detailed_comparison': {},
            'executive_summary': {}
        }
        
        # –°–æ–∑–¥–∞–µ–º —Ä–µ–π—Ç–∏–Ω–≥ —Å–∞–π—Ç–æ–≤
        rankings = self._create_comprehensive_ranking(analysis_results, target_url)
        comparative['ranking'] = rankings
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ–∑–∏—Ü–∏—é —Ü–µ–ª–µ–≤–æ–≥–æ —Å–∞–π—Ç–∞ —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–º
        target_rank = next((r for r in rankings if r['is_target']), None)
        if target_rank:
            target_position = target_rank.get('position', 0)
            total_sites = len(rankings)
            
            comparative['target_ranking'] = {
                'position': target_position,
                'total_sites': total_sites,
                'percentile': ((total_sites - target_position) / total_sites) * 100 if target_position > 0 else 0,
                'competitive_level': self._get_competitive_level(target_position, total_sites)
            }
        else:
            comparative['target_ranking'] = {
                'position': 'N/A',
                'total_sites': len(rankings),
                'percentile': 0,
                'competitive_level': '–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ'
            }
        
        # –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–æ–π –ø–æ–∑–∏—Ü–∏–∏
        comparative['strengths_weaknesses'] = self._analyze_comprehensive_competitive_position(
            analysis_results[target_url], rankings, analysis_results
        )
        
        # –ê–Ω–∞–ª–∏–∑ –º–µ—Ç—Ä–∏–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        comparative['performance_metrics'] = self._analyze_performance_metrics(analysis_results, target_url)
        
        # –ê–Ω–∞–ª–∏–∑ —Ä—ã–Ω–æ—á–Ω–æ–π –ø–æ–∑–∏—Ü–∏–∏
        comparative['market_position_analysis'] = self._analyze_market_position(rankings, target_url)
        
        # –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª —É–ª—É—á—à–µ–Ω–∏–π
        comparative['improvement_potential'] = self._analyze_improvement_potential(
            analysis_results[target_url], rankings
        )
        
        # –î–µ—Ç–∞–ª—å–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ
        comparative['detailed_comparison'] = self._create_detailed_comparison_matrix(analysis_results)
        
        # –°—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        comparative['strategic_recommendations'] = self._generate_strategic_recommendations(
            comparative, analysis_results
        )
        
        # –ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ —Ä–µ–∑—é–º–µ
        comparative['executive_summary'] = self._generate_executive_summary(comparative)
    
        return comparative
    
    def _create_comprehensive_ranking(self, analysis_results: Dict[str, Any], target_url: str) -> List[Dict]:
        """–°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ —Ä–µ–π—Ç–∏–Ω–≥–∞ —Å–∞–π—Ç–æ–≤ —Å –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ–º –ø–æ–∑–∏—Ü–∏–π"""
        rankings = []
        
        for url, analysis in analysis_results.items():
            # –ë–µ—Ä–µ–º GEO –æ—Ü–µ–Ω–∫—É –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω—É—é –º–µ—Ç—Ä–∏–∫—É
            geo_score = analysis.get('overall_geo_score', 0)
            
            # –ï—Å–ª–∏ GEO –æ—Ü–µ–Ω–∫–∏ –Ω–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—â—É—é –æ—Ü–µ–Ω–∫—É
            if geo_score == 0:
                geo_score = analysis.get('score', 0) * 0.8  # –ü—Ä–∏–≤–æ–¥–∏–º –∫ —à–∫–∞–ª–µ GEO
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è —Ä–µ–π—Ç–∏–Ω–≥–∞
            citation_score = analysis.get('citation_potential', geo_score * 0.8)
            semantic_score = analysis.get('semantic_density_score', geo_score * 0.7)
            structure_score = analysis.get('clear_answer_quality', geo_score * 0.75)
            rag_score = analysis.get('rag_optimization_score', geo_score * 0.6)
            
            # –ö–æ–º–ø–æ–∑–∏—Ç–Ω—ã–π —Å–∫–æ—Ä (–≤–∑–≤–µ—à–µ–Ω–Ω–∞—è —Å—É–º–º–∞)
            composite_score = (
                geo_score * 0.4 +
                citation_score * 0.2 +
                semantic_score * 0.15 +
                structure_score * 0.15 +
                rag_score * 0.1
            )
            
            rankings.append({
                'url': url,
                'overall_score': round(composite_score, 1),
                'geo_score': round(geo_score, 1),
                'citation_potential': round(citation_score, 1),
                'semantic_density': round(semantic_score, 1),
                'clear_answers': round(structure_score, 1),
                'rag_score': round(rag_score, 1),
                'is_target': url == target_url,
                'performance_tier': self._get_performance_tier(composite_score)
            })
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–±—ã–≤–∞–Ω–∏—é –æ–±—â–µ–≥–æ —Å–∫–æ—Ä–∞
        rankings.sort(key=lambda x: x['overall_score'], reverse=True)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–∑–∏—Ü–∏–∏ –≤ —Ä–µ–π—Ç–∏–Ω–≥–µ
        for index, rank in enumerate(rankings):
            rank['position'] = index + 1
        
        return rankings
    
    def _get_performance_tier(self, score: float) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Ä–æ–≤–Ω—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        if score >= 85:
            return "–õ–∏–¥–µ—Ä"
        elif score >= 70:
            return "–°–∏–ª—å–Ω—ã–π –∏–≥—Ä–æ–∫"
        elif score >= 55:
            return "–°—Ä–µ–¥–Ω–∏–π —É—Ä–æ–≤–µ–Ω—å"
        elif score >= 40:
            return "–¢—Ä–µ–±—É–µ—Ç —É–ª—É—á—à–µ–Ω–∏–π"
        else:
            return "–û—Ç—Å—Ç–∞—é—â–∏–π"
    
    def _get_competitive_level(self, position: int, total: int) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Ä–æ–≤–Ω—è –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏"""
        if position == 0:
            return "–õ–∏–¥–µ—Ä —Ä—ã–Ω–∫–∞"
        elif position == 1:
            return "–ë–ª–∏–∑–∫–∏–π –ø—Ä–µ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å"
        elif position < total * 0.2:
            return "–í–µ—Ä—Ö–Ω–∏–π —Å–µ–≥–º–µ–Ω—Ç"
        elif position < total * 0.5:
            return "–°—Ä–µ–¥–Ω–∏–π —Å–µ–≥–º–µ–Ω—Ç"
        else:
            return "–ù–∏–∂–Ω–∏–π —Å–µ–≥–º–µ–Ω—Ç"
    
    def _analyze_comprehensive_competitive_position(self, target_analysis: Dict[str, Any], 
                                              rankings: List[Dict], 
                                              all_results: Dict[str, Any]) -> Dict[str, Any]:
        """–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–æ–π –ø–æ–∑–∏—Ü–∏–∏ —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–º –¥–æ—Å—Ç—É–ø–∞ –∫ –ø–æ–∑–∏—Ü–∏–∏"""
        if not rankings:
            return {}
        
        target_rank = next((r for r in rankings if r['is_target']), None)
        if not target_rank:
            return {}
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ –ø–æ–∑–∏—Ü–∏–∏
        target_position = target_rank.get('position', 0)
        
        # –ù–∞—Ö–æ–¥–∏–º –ª–∏–¥–µ—Ä–∞ (–Ω–µ —Ü–µ–ª–µ–≤–æ–≥–æ —Å–∞–π—Ç–∞)
        leader = next((r for r in rankings if not r['is_target']), None)
        
        strengths = []
        weaknesses = []
        opportunities = []
        threats = []
        
        target_score = target_rank['overall_score']
        avg_score = sum(r['overall_score'] for r in rankings) / len(rankings)
        leader_score = leader['overall_score'] if leader else target_score
        
        # –ê–Ω–∞–ª–∏–∑ —Å–∏–ª—å–Ω—ã—Ö —Å—Ç–æ—Ä–æ–Ω
        if target_rank['citation_potential'] > avg_score:
            strengths.append("–í—ã—Å–æ–∫–∏–π –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≤ AI-–æ—Ç–≤–µ—Ç–∞—Ö")
        if target_rank['semantic_density'] > avg_score:
            strengths.append("–û—Ç–ª–∏—á–Ω–∞—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è –ø–ª–æ—Ç–Ω–æ—Å—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç–∞")
        if target_rank['clear_answers'] > avg_score:
            strengths.append("–ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –≥–æ—Ç–æ–≤—ã–µ –æ—Ç–≤–µ—Ç—ã –¥–ª—è snippets")
        if target_rank['rag_score'] > avg_score:
            strengths.append("–•–æ—Ä–æ—à–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è RAG-—Å–∏—Å—Ç–µ–º")
        
        # –ê–Ω–∞–ª–∏–∑ —Å–ª–∞–±—ã—Ö —Å—Ç–æ—Ä–æ–Ω
        if target_rank['citation_potential'] < avg_score:
            weaknesses.append("–ù–∏–∑–∫–∏–π –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞–º–∏")
        if target_rank['rag_score'] < avg_score:
            weaknesses.append("–°–ª–∞–±–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è RAG-—Å–∏—Å—Ç–µ–º")
        if target_rank['semantic_density'] < avg_score:
            weaknesses.append("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–∞—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è –ø–ª–æ—Ç–Ω–æ—Å—Ç—å")
        
        # –ê–Ω–∞–ª–∏–∑ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π
        if leader and target_score < leader_score:
            score_gap = leader_score - target_score
            opportunities.append(f"–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å —É–ª—É—á—à–∏—Ç—å –æ—Ü–µ–Ω–∫—É –Ω–∞ {score_gap:.1f} –±–∞–ª–ª–æ–≤ –¥–ª—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è –ª–∏–¥–µ—Ä—Å—Ç–≤–∞")
        
        # –ê–Ω–∞–ª–∏–∑ —É–≥—Ä–æ–∑
        if target_position > len(rankings) * 0.7:
            threats.append("–†–∏—Å–∫ –ø–æ—Ç–µ—Ä–∏ –ø–æ–∑–∏—Ü–∏–π –≤ –ø–æ–∏—Å–∫–æ–≤–æ–π –≤—ã–¥–∞—á–µ AI-—Å–∏—Å—Ç–µ–º")
        
        return {
            'strengths': strengths,
            'weaknesses': weaknesses,
            'opportunities': opportunities,
            'threats': threats,
            'competitive_gap': leader_score - target_score if leader else 0,
            'market_position': self._determine_market_position(target_rank, rankings),
            'improvement_priority': self._determine_improvement_priority(weaknesses, target_rank),
            'target_position': target_position
        }
        
    def _analyze_performance_metrics(self, analysis_results: Dict[str, Any], target_url: str) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –∫–ª—é—á–µ–≤—ã—Ö –º–µ—Ç—Ä–∏–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        metrics = {
            'target_performance': {},
            'competitor_averages': {},
            'performance_gaps': {},
            'key_insights': []
        }
        
        if target_url not in analysis_results:
            return metrics
        
        target_data = analysis_results[target_url]
        competitor_data = [data for url, data in analysis_results.items() if url != target_url]
        
        # –ú–µ—Ç—Ä–∏–∫–∏ —Ü–µ–ª–µ–≤–æ–≥–æ —Å–∞–π—Ç–∞
        metrics['target_performance'] = {
            'geo_score': target_data.get('overall_geo_score', 0),
            'citation_potential': target_data.get('citation_potential', 0),
            'semantic_density': target_data.get('semantic_density_score', 0),
            'content_quality': target_data.get('clear_answer_quality', 0),
            'rag_optimization': target_data.get('rag_optimization_score', 0)
        }
        
        # –°—Ä–µ–¥–Ω–∏–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤
        if competitor_data:
            metrics['competitor_averages'] = {
                'geo_score': sum(d.get('overall_geo_score', 0) for d in competitor_data) / len(competitor_data),
                'citation_potential': sum(d.get('citation_potential', 0) for d in competitor_data) / len(competitor_data),
                'semantic_density': sum(d.get('semantic_density_score', 0) for d in competitor_data) / len(competitor_data),
                'content_quality': sum(d.get('clear_answer_quality', 0) for d in competitor_data) / len(competitor_data),
                'rag_optimization': sum(d.get('rag_optimization_score', 0) for d in competitor_data) / len(competitor_data)
            }
            
            # –†–∞—Å—á–µ—Ç —Ä–∞–∑—Ä—ã–≤–æ–≤
            target_perf = metrics['target_performance']
            competitor_avg = metrics['competitor_averages']
            
            metrics['performance_gaps'] = {
                metric: target_perf[metric] - competitor_avg[metric]
                for metric in target_perf.keys()
            }
            
            # –ö–ª—é—á–µ–≤—ã–µ –∏–Ω—Å–∞–π—Ç—ã
            for metric, gap in metrics['performance_gaps'].items():
                if gap > 10:
                    metrics['key_insights'].append(f"üìà –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–æ –≤ {metric}: +{gap:.1f} –±–∞–ª–ª–æ–≤")
                elif gap < -10:
                    metrics['key_insights'].append(f"üìâ –û—Ç—Å—Ç–∞–≤–∞–Ω–∏–µ –≤ {metric}: {gap:.1f} –±–∞–ª–ª–æ–≤")
        
        return metrics
    
    def _analyze_market_position(self, rankings: List[Dict], target_url: str) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ —Ä—ã–Ω–æ—á–Ω–æ–π –ø–æ–∑–∏—Ü–∏–∏ —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–º –¥–æ—Å—Ç—É–ø–∞ –∫ –ø–æ–∑–∏—Ü–∏–∏"""
        target_rank = next((r for r in rankings if r['is_target']), None)
        if not target_rank:
            return {}
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ –ø–æ–∑–∏—Ü–∏–∏
        position = target_rank.get('position', 0)
        total = len(rankings)
        
        return {
            'current_position': position,
            'total_competitors': total - 1,
            'market_share_estimate': self._estimate_market_share(position, total),
            'competitive_intensity': self._calculate_competitive_intensity(rankings),
            'growth_potential': self._assess_growth_potential(position, total),
            'strategic_priority': self._determine_strategic_priority(position, total)
        }
    
    def _estimate_market_share(self, position: int, total: int) -> str:
        """–û—Ü–µ–Ω–∫–∞ –¥–æ–ª–∏ —Ä—ã–Ω–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ–∑–∏—Ü–∏–∏"""
        if position == 1:
            return "–õ–∏–¥–µ—Ä —Ä—ã–Ω–∫–∞ (25%+)"
        elif position <= 3:
            return "–ó–Ω–∞—á–∏—Ç–µ–ª—å–Ω–∞—è –¥–æ–ª—è (15-25%)"
        elif position <= total * 0.3:
            return "–°—Ä–µ–¥–Ω—è—è –¥–æ–ª—è (5-15%)"
        else:
            return "–ù–µ–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–∞—è –¥–æ–ª—è (<5%)"
    
    def _calculate_competitive_intensity(self, rankings: List[Dict]) -> str:
        """–†–∞—Å—á–µ—Ç –∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç–∏ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ü–∏–∏"""
        if len(rankings) < 3:
            return "–ù–∏–∑–∫–∞—è"
        
        score_range = rankings[0]['overall_score'] - rankings[-1]['overall_score']
        if score_range < 20:
            return "–í—ã—Å–æ–∫–∞—è"
        elif score_range < 40:
            return "–°—Ä–µ–¥–Ω—è—è"
        else:
            return "–ù–∏–∑–∫–∞—è"
    
    def _assess_growth_potential(self, position: int, total: int) -> str:
        """–û—Ü–µ–Ω–∫–∞ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª–∞ —Ä–æ—Å—Ç–∞"""
        if position == 1:
            return "–û–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–π - –ø–æ–¥–¥–µ—Ä–∂–∞–Ω–∏–µ –ª–∏–¥–µ—Ä—Å—Ç–≤–∞"
        elif position <= 3:
            return "–í—ã—Å–æ–∫–∏–π - –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å —Å—Ç–∞—Ç—å –ª–∏–¥–µ—Ä–æ–º"
        elif position <= total * 0.5:
            return "–°—Ä–µ–¥–Ω–∏–π - –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ"
        else:
            return "–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π - –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ"
    
    def _determine_strategic_priority(self, position: int, total: int) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–æ–≥–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞"""
        if position == 1:
            return "–ó–∞—â–∏—Ç–∞ –ø–æ–∑–∏—Ü–∏–π –∏ –∏–Ω–Ω–æ–≤–∞—Ü–∏–∏"
        elif position <= 3:
            return "–ê—Ç–∞–∫–∞ –Ω–∞ –ª–∏–¥–µ—Ä–∞"
        elif position <= total * 0.5:
            return "–ö–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏—è –∏ —Ä–æ—Å—Ç"
        else:
            return "–í—ã–∂–∏–≤–∞–Ω–∏–µ –∏ —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è"
    
    def _analyze_improvement_potential(self, target_analysis: Dict[str, Any], rankings: List[Dict]) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª–∞ —É–ª—É—á—à–µ–Ω–∏–π"""
        target_rank = next((r for r in rankings if r['is_target']), None)
        if not target_rank:
            return {}
        
        leader = next((r for r in rankings if not r['is_target']), None)
        
        return {
            'immediate_improvements': self._identify_immediate_improvements(target_analysis),
            'strategic_improvements': self._identify_strategic_improvements(target_rank, leader),
            'quick_wins': self._identify_quick_wins(target_analysis),
            'long_term_initiatives': self._identify_long_term_initiatives(target_rank, leader),
            'estimated_impact': self._estimate_improvement_impact(target_rank, leader)
        }
    
    def _identify_immediate_improvements(self, target_analysis: Dict[str, Any]) -> List[str]:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–µ–º–µ–¥–ª–µ–Ω–Ω—ã—Ö —É–ª—É—á—à–µ–Ω–∏–π"""
        improvements = []
        
        # –ê–Ω–∞–ª–∏–∑ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö —Ü–µ–ª–µ–≤–æ–≥–æ —Å–∞–π—Ç–∞
        if target_analysis.get('citation_potential', 0) < 70:
            improvements.append("–£–≤–µ–ª–∏—á–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ clear answers –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
        
        if target_analysis.get('semantic_density_score', 0) < 65:
            improvements.append("–£–ª—É—á—à–∏—Ç—å —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫—É—é –ø–ª–æ—Ç–Ω–æ—Å—Ç—å —á–µ—Ä–µ–∑ —É–≥–ª—É–±–ª–µ–Ω–∏–µ —Ç–µ–º–∞—Ç–∏–∫–∏")
        
        if target_analysis.get('rag_optimization_score', 0) < 60:
            improvements.append("–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç –¥–ª—è RAG-—Å–∏—Å—Ç–µ–º")
        
        return improvements[:3]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ç—Ä–µ–º—è –Ω–∞–∏–±–æ–ª–µ–µ –≤–∞–∂–Ω—ã–º–∏
    
    def _identify_strategic_improvements(self, target_rank: Dict, leader: Dict) -> List[str]:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏—Ö —É–ª—É—á—à–µ–Ω–∏–π"""
        improvements = []
        
        if leader:
            gap = leader['overall_score'] - target_rank['overall_score']
            if gap > 20:
                improvements.append(f"–†–∞–∑—Ä–∞–±–æ—Ç–∞—Ç—å –∫–æ–º–ø–ª–µ–∫—Å–Ω—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é —É–ª—É—á—à–µ–Ω–∏—è GEO-–ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π (—Ä–∞–∑—Ä—ã–≤: {gap:.1f} –±–∞–ª–ª–æ–≤)")
        
        if target_rank['performance_tier'] in ["–¢—Ä–µ–±—É–µ—Ç —É–ª—É—á—à–µ–Ω–∏–π", "–û—Ç—Å—Ç–∞—é—â–∏–π"]:
            improvements.append("–ü—Ä–æ–≤–µ—Å—Ç–∏ –ø–æ–ª–Ω—ã–π –∞—É–¥–∏—Ç –∏ —Ä–µ–¥–∏–∑–∞–π–Ω –∫–æ–Ω—Ç–µ–Ω—Ç–Ω–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏")
        
        return improvements
    
    def _identify_quick_wins(self, target_analysis: Dict[str, Any]) -> List[str]:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –±—ã—Å—Ç—Ä—ã—Ö –ø–æ–±–µ–¥"""
        quick_wins = []
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –ø—Ä–æ—Å—Ç—ã—Ö –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø—Ä–æ–±–ª–µ–º
        llm_analysis = target_analysis.get('llm_analysis', {})
        if llm_analysis:
            recommendations = llm_analysis.get('geo_recommendations', [])
            # –ò—â–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–∂–Ω–æ –±—ã—Å—Ç—Ä–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å
            quick_keywords = ['–¥–æ–±–∞–≤–∏—Ç—å', '—É–≤–µ–ª–∏—á–∏—Ç—å', '–∏—Å–ø—Ä–∞–≤–∏—Ç—å', '–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å']
            for rec in recommendations:
                if any(keyword in rec.lower() for keyword in quick_keywords):
                    if len(rec) < 100:  # –ö–æ—Ä–æ—Ç–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –æ–±—ã—á–Ω–æ –ø—Ä–æ—â–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å
                        quick_wins.append(rec)
        
        return quick_wins[:5]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –ø—è—Ç—å—é
    
    def _identify_long_term_initiatives(self, target_rank: Dict, leader: Dict) -> List[str]:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã—Ö –∏–Ω–∏—Ü–∏–∞—Ç–∏–≤"""
        initiatives = []
        
        if target_rank['performance_tier'] != "–õ–∏–¥–µ—Ä":
            initiatives.append("–í–Ω–µ–¥—Ä–µ–Ω–∏–µ AI-–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –∫–æ–Ω—Ç–µ–Ω—Ç–Ω–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏")
            initiatives.append("–†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ —Å–∏—Å—Ç–µ–º—ã –ø–æ—Å—Ç–æ—è–Ω–Ω–æ–≥–æ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ GEO-–º–µ—Ç—Ä–∏–∫")
            initiatives.append("–°–æ–∑–¥–∞–Ω–∏–µ —Ü–µ–Ω—Ç—Ä–∞ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π –ø–æ –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω–æ–º—É –ø–æ–∏—Å–∫—É")
        
        return initiatives
    
    def _estimate_improvement_impact(self, target_rank: Dict, leader: Dict) -> Dict[str, Any]:
        """–û—Ü–µ–Ω–∫–∞ –≤–ª–∏—è–Ω–∏—è —É–ª—É—á—à–µ–Ω–∏–π"""
        if not leader:
            return {}
        
        current_score = target_rank['overall_score']
        leader_score = leader['overall_score']
        gap = leader_score - current_score
        
        return {
            'current_position': f"{current_score:.1f}/100",
            'leader_score': f"{leader_score:.1f}/100",
            'performance_gap': f"{gap:.1f} –±–∞–ª–ª–æ–≤",
            'estimated_improvement_timeline': self._estimate_timeline(gap),
            'potential_position_improvement': self._estimate_position_improvement(current_score, leader_score),
            'roi_estimate': self._estimate_roi(gap)
        }
    
    def _estimate_timeline(self, gap: float) -> str:
        """–û—Ü–µ–Ω–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä–∞–º–æ–∫ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏–π"""
        if gap < 10:
            return "1-2 –º–µ—Å—è—Ü–∞"
        elif gap < 25:
            return "3-6 –º–µ—Å—è—Ü–µ–≤"
        elif gap < 40:
            return "6-12 –º–µ—Å—è—Ü–µ–≤"
        else:
            return "–ë–æ–ª–µ–µ 1 –≥–æ–¥–∞"
    
    def _estimate_position_improvement(self, current_score: float, leader_score: float) -> str:
        """–û—Ü–µ–Ω–∫–∞ —É–ª—É—á—à–µ–Ω–∏—è –ø–æ–∑–∏—Ü–∏–∏"""
        improvement = (leader_score - current_score) / 10  # –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
        if improvement >= 3:
            return "–ó–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ –ø–æ–∑–∏—Ü–∏–π"
        elif improvement >= 1.5:
            return "–£–º–µ—Ä–µ–Ω–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ"
        else:
            return "–ù–µ–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ"
    
    def _estimate_roi(self, gap: float) -> str:
        """–û—Ü–µ–Ω–∫–∞ –≤–æ–∑–≤—Ä–∞—Ç–∞ –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–π"""
        if gap < 15:
            return "–í—ã—Å–æ–∫–∏–π ROI - –±—ã—Å—Ç—Ä–∞—è –æ–∫—É–ø–∞–µ–º–æ—Å—Ç—å"
        elif gap < 30:
            return "–°—Ä–µ–¥–Ω–∏–π ROI - —É–º–µ—Ä–µ–Ω–Ω–∞—è –æ–∫—É–ø–∞–µ–º–æ—Å—Ç—å"
        else:
            return "–ù–∏–∑–∫–∏–π ROI - –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã–µ –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏"
    
    def _create_detailed_comparison_matrix(self, analysis_results: Dict[str, Any]) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞–Ω–∏–µ –¥–µ—Ç–∞–ª—å–Ω–æ–π –º–∞—Ç—Ä–∏—Ü—ã —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"""
        comparison = {
            'metrics_comparison': {},
            'category_breakdown': {},
            'competitive_advantages': {},
            'benchmark_analysis': {}
        }
        
        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
        metrics = ['overall_geo_score', 'citation_potential', 'semantic_density_score', 
                  'clear_answer_quality', 'rag_optimization_score']
        
        for metric in metrics:
            comparison['metrics_comparison'][metric] = {}
            for url, analysis in analysis_results.items():
                if metric in analysis:
                    comparison['metrics_comparison'][metric][url] = analysis[metric]
                elif 'llm_analysis' in analysis and metric in analysis['llm_analysis']:
                    comparison['metrics_comparison'][metric][url] = analysis['llm_analysis'][metric]
        
        # –ê–Ω–∞–ª–∏–∑ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω—ã—Ö –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤
        for url, analysis in analysis_results.items():
            advantages = []
            disadvantages = []
            
            for other_url, other_analysis in analysis_results.items():
                if url != other_url:
                    # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
                    url_score = analysis.get('overall_geo_score', 0)
                    other_score = other_analysis.get('overall_geo_score', 0)
                    
                    if url_score > other_score + 10:
                        advantages.append(f"–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–æ –ø–µ—Ä–µ–¥ {other_url}: +{url_score - other_score:.1f} –±–∞–ª–ª–æ–≤")
                    elif url_score < other_score - 10:
                        disadvantages.append(f"–û—Ç—Å—Ç–∞–≤–∞–Ω–∏–µ –æ—Ç {other_url}: {other_score - url_score:.1f} –±–∞–ª–ª–æ–≤")
            
            comparison['competitive_advantages'][url] = {
                'advantages': advantages[:3],  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ç—Ä–µ–º—è
                'disadvantages': disadvantages[:3]
            }
        
        # –ë–µ–Ω—á–º–∞—Ä–∫-–∞–Ω–∞–ª–∏–∑
        if len(analysis_results) > 1:
            scores = [analysis.get('overall_geo_score', 0) for analysis in analysis_results.values()]
            comparison['benchmark_analysis'] = {
                'industry_average': sum(scores) / len(scores),
                'industry_leader': max(scores),
                'performance_benchmark': self._calculate_performance_benchmark(scores),
                'gap_analysis': self._perform_gap_analysis(scores)
            }
        
        return comparison
    
    def _calculate_performance_benchmark(self, scores: List[float]) -> Dict[str, float]:
        """–†–∞—Å—á–µ—Ç –±–µ–Ω—á–º–∞—Ä–∫–æ–≤ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        return {
            'excellent_threshold': max(scores) * 0.9,  # 90% –æ—Ç –ª–∏–¥–µ—Ä–∞
            'good_threshold': sum(scores) / len(scores),  # –°—Ä–µ–¥–Ω–µ–µ –ø–æ –æ—Ç—Ä–∞—Å–ª–∏
            'poor_threshold': min(scores) * 1.1  # –ù–∞ 10% –ª—É—á—à–µ —Ö—É–¥—à–µ–≥–æ
        }
    
    def _perform_gap_analysis(self, scores: List[float]) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ —Ä–∞–∑—Ä—ã–≤–æ–≤"""
        sorted_scores = sorted(scores, reverse=True)
        return {
            'leader_gap': sorted_scores[0] - sorted_scores[1] if len(sorted_scores) > 1 else 0,
            'average_gap': sorted_scores[0] - (sum(scores) / len(scores)),
            'competitive_range': sorted_scores[0] - sorted_scores[-1]
        }
    
    def _determine_improvement_priority(self, weaknesses: List[str], target_rank: Dict) -> List[str]:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–≤ —É–ª—É—á—à–µ–Ω–∏–π"""
        priorities = []
        
        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–ª–∞–±—ã—Ö —Å—Ç–æ—Ä–æ–Ω
        weakness_priority = {
            '—Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è': '–í—ã—Å–æ–∫–∏–π',
            'RAG': '–í—ã—Å–æ–∫–∏–π', 
            '—Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è': '–°—Ä–µ–¥–Ω–∏–π',
            '—Å—Ç—Ä—É–∫—Ç—É—Ä': '–°—Ä–µ–¥–Ω–∏–π',
            '—Ç–µ—Ö–Ω–∏—á–µ—Å–∫': '–ù–∏–∑–∫–∏–π'
        }
        
        for weakness in weaknesses:
            for key, priority in weakness_priority.items():
                if key in weakness.lower():
                    priorities.append(f"{priority}: {weakness}")
                    break
        
        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ–∑–∏—Ü–∏–∏
        if target_rank['performance_tier'] in ["–¢—Ä–µ–±—É–µ—Ç —É–ª—É—á—à–µ–Ω–∏–π", "–û—Ç—Å—Ç–∞—é—â–∏–π"]:
            priorities.append("–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π: –§—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ GEO-–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏")
        
        return priorities[:5]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –ø—è—Ç—å—é –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞–º–∏
    
    def _generate_comprehensive_summary(self, comparative_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–π —Å–≤–æ–¥–∫–∏ –∞–Ω–∞–ª–∏–∑–∞"""
        target_ranking = comparative_analysis.get('target_ranking', {})
        performance_metrics = comparative_analysis.get('performance_metrics', {})
        market_position = comparative_analysis.get('market_position_analysis', {})
        improvement_potential = comparative_analysis.get('improvement_potential', {})
        
        return {
            'overall_assessment': self._generate_overall_assessment(target_ranking),
            'key_findings': self._extract_key_findings(comparative_analysis),
            'strategic_implications': self._derive_strategic_implications(market_position),
            'action_plan': self._create_action_plan(improvement_potential),
            'success_metrics': self._define_success_metrics(performance_metrics),
            'risk_assessment': self._assess_risks(market_position, improvement_potential)
        }
    
    def _generate_overall_assessment(self, target_ranking: Dict[str, Any]) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–±—â–µ–π –æ—Ü–µ–Ω–∫–∏"""
        position = target_ranking.get('position', 'N/A')
        total = target_ranking.get('total_sites', 0)
        percentile = target_ranking.get('percentile', 0)
        level = target_ranking.get('competitive_level', 'N/A')
        
        if position == 1:
            return f"üéØ –õ–∏–¥–∏—Ä—É—é—â–∞—è –ø–æ–∑–∏—Ü–∏—è –Ω–∞ —Ä—ã–Ω–∫–µ ({position}/{total}, {percentile:.1f}% –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—å)"
        elif position <= 3:
            return f"üìà –°–∏–ª—å–Ω–∞—è –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–∞—è –ø–æ–∑–∏—Ü–∏—è ({position}/{total}, {percentile:.1f}% –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—å)"
        elif position <= total * 0.5:
            return f"üìä –°—Ä–µ–¥–Ω—è—è –ø–æ–∑–∏—Ü–∏—è —Å –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª–æ–º —Ä–æ—Å—Ç–∞ ({position}/{total}, {percentile:.1f}% –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—å)"
        else:
            return f"‚ö†Ô∏è –¢—Ä–µ–±—É–µ—Ç –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã—Ö —É–ª—É—á—à–µ–Ω–∏–π ({position}/{total}, {percentile:.1f}% –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—å)"
    
    def _extract_key_findings(self, comparative_analysis: Dict[str, Any]) -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö –Ω–∞—Ö–æ–¥–æ–∫"""
        findings = []
        
        # –ü–æ–∑–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ
        position = comparative_analysis['target_ranking']['position']
        total = comparative_analysis['target_ranking']['total_sites']
        findings.append(f"–¢–µ–∫—É—â–∞—è –ø–æ–∑–∏—Ü–∏—è: {position} –∏–∑ {total} —Å–∞–π—Ç–æ–≤")
        
        # –°–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã
        strengths = comparative_analysis['strengths_weaknesses'].get('strengths', [])
        if strengths:
            findings.append(f"–ö–ª—é—á–µ–≤—ã–µ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞: {', '.join(strengths[:2])}")
        
        # –°–ª–∞–±—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã
        weaknesses = comparative_analysis['strengths_weaknesses'].get('weaknesses', [])
        if weaknesses:
            findings.append(f"–û—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã: {', '.join(weaknesses[:2])}")
        
        # –†–∞–∑—Ä—ã–≤ —Å –ª–∏–¥–µ—Ä–æ–º
        gap = comparative_analysis['strengths_weaknesses'].get('competitive_gap', 0)
        if gap > 0:
            findings.append(f"–†–∞–∑—Ä—ã–≤ —Å –ª–∏–¥–µ—Ä–æ–º: {gap:.1f} –±–∞–ª–ª–æ–≤")
        
        return findings
    
    def _derive_strategic_implications(self, market_position: Dict[str, Any]) -> List[str]:
        """–í—ã–≤–æ–¥ —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏—Ö –∏–º–ø–ª–∏–∫–∞—Ü–∏–π"""
        implications = []
        
        priority = market_position.get('strategic_priority', '')
        growth_potential = market_position.get('growth_potential', '')
        intensity = market_position.get('competitive_intensity', '')
        
        implications.append(f"–°—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç: {priority}")
        implications.append(f"–ü–æ—Ç–µ–Ω—Ü–∏–∞–ª —Ä–æ—Å—Ç–∞: {growth_potential}")
        implications.append(f"–ò–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç—å –∫–æ–Ω–∫—É—Ä–µ–Ω—Ü–∏–∏: {intensity}")
        
        return implications
    
    def _create_action_plan(self, improvement_potential: Dict[str, Any]) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø–ª–∞–Ω–∞ –¥–µ–π—Å—Ç–≤–∏–π"""
        return {
            'immediate_actions': improvement_potential.get('immediate_improvements', []),
            'quick_wins': improvement_potential.get('quick_wins', []),
            'strategic_initiatives': improvement_potential.get('strategic_improvements', []),
            'long_term_goals': improvement_potential.get('long_term_initiatives', []),
            'implementation_timeline': improvement_potential.get('estimated_impact', {}).get('estimated_improvement_timeline', '')
        }
    
    def _define_success_metrics(self, performance_metrics: Dict[str, Any]) -> List[str]:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ —É—Å–ø–µ—Ö–∞"""
        metrics = []
        
        gaps = performance_metrics.get('performance_gaps', {})
        for metric, gap in gaps.items():
            if gap > 0:
                metrics.append(f"–£–≤–µ–ª–∏—á–∏—Ç—å –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–æ –≤ {metric}")
            else:
                metrics.append(f"–°–æ–∫—Ä–∞—Ç–∏—Ç—å –æ—Ç—Å—Ç–∞–≤–∞–Ω–∏–µ –≤ {metric}")
        
        return metrics[:3]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ç—Ä–µ–º—è
    
    def _assess_risks(self, market_position: Dict[str, Any], improvement_potential: Dict[str, Any]) -> List[str]:
        """–û—Ü–µ–Ω–∫–∞ —Ä–∏—Å–∫–æ–≤"""
        risks = []
        
        position = market_position.get('current_position', 0)
        total = market_position.get('total_competitors', 0) + 1
        
        if position > total * 0.7:
            risks.append("–í—ã—Å–æ–∫–∏–π —Ä–∏—Å–∫ –ø–æ—Ç–µ—Ä–∏ –≤–∏–¥–∏–º–æ—Å—Ç–∏ –≤ AI-–ø–æ–∏—Å–∫–µ")
        
        if improvement_potential.get('estimated_impact', {}).get('roi_estimate', '').startswith('–ù–∏–∑–∫–∏–π'):
            risks.append("–ù–∏–∑–∫–∞—è –æ–∫—É–ø–∞–µ–º–æ—Å—Ç—å –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–π –≤ —É–ª—É—á—à–µ–Ω–∏—è")
        
        intensity = market_position.get('competitive_intensity', '')
        if intensity == '–í—ã—Å–æ–∫–∞—è':
            risks.append("–í—ã—Å–æ–∫–∞—è –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–∞—è –Ω–∞–ø—Ä—è–∂–µ–Ω–Ω–æ—Å—Ç—å —Ç—Ä–µ–±—É–µ—Ç –ø–æ—Å—Ç–æ—è–Ω–Ω—ã—Ö —É–ª—É—á—à–µ–Ω–∏–π")
        
        return risks
    
    def _generate_executive_summary(self, comparative_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ä–µ–∑—é–º–µ"""
        return {
            'overview': self._create_executive_overview(comparative_analysis),
            'competitive_position': self._summarize_competitive_position(comparative_analysis),
            'key_recommendations': self._prioritize_recommendations(comparative_analysis),
            'expected_outcomes': self._project_expected_outcomes(comparative_analysis),
            'next_steps': self._define_next_steps(comparative_analysis)
        }
    
    def _create_executive_overview(self, comparative_analysis: Dict[str, Any]) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ –æ–±–∑–æ—Ä–∞ –¥–ª—è —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞"""
        target_ranking = comparative_analysis['target_ranking']
        position = target_ranking['position']
        total = target_ranking['total_sites']
        level = target_ranking['competitive_level']
        
        return f"""
        –ê–Ω–∞–ª–∏–∑ –≤—ã—è–≤–∏–ª, —á—Ç–æ —Ü–µ–ª–µ–≤–æ–π —Å–∞–π—Ç –∑–∞–Ω–∏–º–∞–µ—Ç {position}-—é –ø–æ–∑–∏—Ü–∏—é –∏–∑ {total} –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö 
        –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤, —á—Ç–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —É—Ä–æ–≤–Ω—é '{level}'. –û—Å–Ω–æ–≤–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –≤–∫–ª—é—á–∞—é—Ç 
        –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –∏ —É—Å–∏–ª–µ–Ω–∏–µ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω—ã—Ö –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤.
        """
    
    def _summarize_competitive_position(self, comparative_analysis: Dict[str, Any]) -> str:
        """–†–µ–∑—é–º–µ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–æ–π –ø–æ–∑–∏—Ü–∏–∏"""
        swot = comparative_analysis['strengths_weaknesses']
        strengths_count = len(swot.get('strengths', []))
        weaknesses_count = len(swot.get('weaknesses', []))
        gap = swot.get('competitive_gap', 0)
        
        return f"""
        –°–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã: {strengths_count} –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ
        –û–±–ª–∞—Å—Ç–∏ —É–ª—É—á—à–µ–Ω–∏—è: {weaknesses_count} –≤—ã—è–≤–ª–µ–Ω–æ
        –†–∞–∑—Ä—ã–≤ —Å –ª–∏–¥–µ—Ä–æ–º: {gap:.1f} –±–∞–ª–ª–æ–≤
        """
    
    def _prioritize_recommendations(self, comparative_analysis: Dict[str, Any]) -> List[str]:
        """–ü—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"""
        recommendations = comparative_analysis.get('strategic_recommendations', [])
        improvement = comparative_analysis.get('improvement_potential', {})
        quick_wins = improvement.get('quick_wins', [])
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∏ –ø—Ä–∏–æ—Ä–∏—Ç–∏–∑–∏—Ä—É–µ–º
        all_recs = quick_wins[:2] + recommendations[:3]  # 2 –±—ã—Å—Ç—Ä—ã—Ö –ø–æ–±–µ–¥—ã + 3 —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏—Ö
        return all_recs
    
    def _project_expected_outcomes(self, comparative_analysis: Dict[str, Any]) -> List[str]:
        """–ü—Ä–æ–µ–∫—Ü–∏—è –æ–∂–∏–¥–∞–µ–º—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        outcomes = []
        target_ranking = comparative_analysis['target_ranking']
        position = target_ranking['position']
        total = target_ranking['total_sites']
        
        if position > 1:
            outcomes.append(f"–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –ø–æ–¥–Ω—è—Ç—å—Å—è –Ω–∞ {min(3, position-1)} –ø–æ–∑–∏—Ü–∏—é –≤ —Ä–µ–π—Ç–∏–Ω–≥–µ")
        
        improvement = comparative_analysis.get('improvement_potential', {})
        impact = improvement.get('estimated_impact', {})
        timeline = impact.get('estimated_improvement_timeline', '')
        
        if timeline:
            outcomes.append(f"–ó–∞–º–µ—Ç–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è –æ–∂–∏–¥–∞—é—Ç—Å—è —á–µ—Ä–µ–∑ {timeline}")
        
        return outcomes
    
    def _define_next_steps(self, comparative_analysis: Dict[str, Any]) -> List[str]:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–ª–µ–¥—É—é—â–∏—Ö —à–∞–≥–æ–≤"""
        return [
            "–†–∞–∑—Ä–∞–±–æ—Ç–∞—Ç—å –¥–µ—Ç–∞–ª—å–Ω—ã–π –ø–ª–∞–Ω —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π",
            "–ù–∞–∑–Ω–∞—á–∏—Ç—å –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∑–∞ –∫–∞–∂–¥–æ–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —É–ª—É—á—à–µ–Ω–∏–π",
            "–£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å KPI –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞",
            "–ó–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞—Ç—å –ø–æ–≤—Ç–æ—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ 3 –º–µ—Å—è—Ü–∞"
        ]

    def _fetch_content_data(self, url: str) -> Optional[Dict[str, Any]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –±–∞–∑–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –¥–ª—è LLM-–∞–Ω–∞–ª–∏–∑–∞"""
        try:
            import requests
            from bs4 import BeautifulSoup
            
            response = requests.get(url, timeout=10, headers={
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            })
            
            if response.status_code != 200:
                return None
            
            soup = BeautifulSoup(response.text, 'html.parser')
            
            content_data = {
                'basic_info': {
                    'url': url,
                    'title': soup.title.string if soup.title else '–ù–µ –Ω–∞–π–¥–µ–Ω',
                    'status_code': response.status_code
                },
                'metadata': {
                    'title': {
                        'value': soup.title.string if soup.title else None,
                        'length': len(soup.title.string) if soup.title else 0
                    },
                    'description': {
                        'value': soup.find('meta', attrs={'name': 'description'}).get('content') 
                                 if soup.find('meta', attrs={'name': 'description'}) else None
                    }
                },
                'content_structure': {
                    'readability_sample_text': self._extract_clean_text_for_llm(soup)
                }
            }
            
            return content_data
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {url}: {str(e)}")
            return None

    def _extract_clean_text_for_llm(self, soup):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —á–∏—Å—Ç–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è LLM-–∞–Ω–∞–ª–∏–∑–∞"""
        for script in soup(["script", "style"]):
            script.decompose()
        
        content_areas = soup.find_all(['main', 'article', 'section', 'div'], 
                                    class_=re.compile(r'content|main|article', re.I))
        
        if content_areas:
            text_parts = []
            for area in content_areas[:3]:
                text = area.get_text(strip=True)
                if len(text) > 100:
                    text_parts.append(text)
            
            if text_parts:
                return ' '.join(text_parts)[:3000]
        
        return soup.get_text(strip=True)[:3000]

    def _find_competitors_with_deepseek(self, target_url: str, max_competitors: int = 5) -> List[str]:
        """–ü–æ–∏—Å–∫ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤/–∞–Ω–∞–ª–æ–≥–∏—á–Ω—ã—Ö —Å–∞–π—Ç–æ–≤ —á–µ—Ä–µ–∑ DeepSeek"""
        try:
            cache_key = f"competitors_{target_url}"
            if cache_key in self.competitor_cache:
                return self.competitor_cache[cache_key][:max_competitors]
            
            prompt = f"""
            –¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É –≤–µ–±-—Å–∞–π—Ç–æ–≤ –∏ –ø–æ–∏—Å–∫–æ–≤–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏. 
            –ù–∞–π–¥–∏ {max_competitors} —Å–∞–π—Ç–æ–≤-–∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤ –∏–ª–∏ –∞–Ω–∞–ª–æ–≥–∏—á–Ω—ã—Ö –ø–æ —Ç–µ–º–∞—Ç–∏–∫–µ –≤–µ–±-—Ä–µ—Å—É—Ä—Å–æ–≤ –¥–ª—è: {target_url}

            –ö—Ä–∏—Ç–µ—Ä–∏–∏ –ø–æ–∏—Å–∫–∞:
            - –°—Ö–æ–∂–∞—è —Ç–µ–º–∞—Ç–∏–∫–∞ –∏ –Ω–∏—à–∞
            - –°–æ–ø–æ—Å—Ç–∞–≤–∏–º—ã–π –º–∞—Å—à—Ç–∞–± –∏ –∞—É–¥–∏—Ç–æ—Ä–∏—è
            - –†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –∞–Ω–∞–ª–æ–≥–∏ –ø–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—é
            - –ò–∑–≤–µ—Å—Ç–Ω—ã–µ —Å–∞–π—Ç—ã –≤ —Ç–æ–π –∂–µ –æ–±–ª–∞—Å—Ç–∏

            –í–ê–ñ–ù–û: –í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û JSON –º–∞—Å—Å–∏–≤ —Å URL –≤ —Ñ–æ—Ä–º–∞—Ç–µ:
            ["url1", "url2", "url3", ...]

            –ù–µ –¥–æ–±–∞–≤–ª—è–π –Ω–∏–∫–∞–∫–æ–≥–æ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞, —Ç–æ–ª—å–∫–æ —á–∏—Å—Ç—ã–π JSON.
            """
            
            completion = self.client.chat.completions.create(
                model=self.llm_models['deepseek'],
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3,
                max_tokens=1000
            )
        
            response_text = completion.choices[0].message.content
            
            try:
                competitors = json.loads(response_text)
                if isinstance(competitors, list) and all(isinstance(url, str) for url in competitors):
                    self.competitor_cache[cache_key] = competitors
                    return competitors[:max_competitors]
            except json.JSONDecodeError:
                urls = re.findall(r'https?://[^\s"\']+', response_text)
                self.competitor_cache[cache_key] = urls
                return urls[:max_competitors]
                
            return []
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤: {str(e)}")
            return []

    def _determine_market_position(self, target_rank: Dict, rankings: List[Dict]) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä—ã–Ω–æ—á–Ω–æ–π –ø–æ–∑–∏—Ü–∏–∏"""
        position = next((i for i, r in enumerate(rankings) if r['is_target']), -1)
        total = len(rankings)
        
        if position == 0:
            return "–õ–∏–¥–µ—Ä —Ä—ã–Ω–∫–∞"
        elif position == 1:
            return "–ë–ª–∏–∑–∫–∏–π –ø—Ä–µ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å"
        elif position < total * 0.3:
            return "–í–µ—Ä—Ö–Ω–∏–π —Å–µ–≥–º–µ–Ω—Ç"
        elif position < total * 0.7:
            return "–°—Ä–µ–¥–Ω–∏–π —Å–µ–≥–º–µ–Ω—Ç"
        else:
            return "–ù–∏–∂–Ω–∏–π —Å–µ–≥–º–µ–Ω—Ç"

    def _generate_strategic_recommendations(self, comparative: Dict[str, Any], 
                                          analysis_results: Dict[str, Any]) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"""
        recommendations = []
        target_url = comparative['target_url']
        
        if target_url not in analysis_results:
            return recommendations
        
        target_analysis = analysis_results[target_url]
        competitive_analysis = comparative['strengths_weaknesses']
        
        position = comparative['target_ranking']['position']
        total = comparative['target_ranking']['total_sites']
        
        if position == 1:
            recommendations.append("–£–∫—Ä–µ–ø–ª—è–π—Ç–µ –ª–∏–¥–∏—Ä—É—é—â–∏–µ –ø–æ–∑–∏—Ü–∏–∏ —á–µ—Ä–µ–∑ –∏–Ω–Ω–æ–≤–∞—Ü–∏–∏ –≤ GEO-–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏")
            recommendations.append("–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ —Å –Ω–æ–≤—ã–º–∏ —Ñ–æ—Ä–º–∞—Ç–∞–º–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –¥–ª—è AI")
        elif position <= 3:
            recommendations.append(f"–°—Ñ–æ–∫—É—Å–∏—Ä—É–π—Ç–µ—Å—å –Ω–∞ –ø—Ä–µ–æ–¥–æ–ª–µ–Ω–∏–∏ —Ä–∞–∑—Ä—ã–≤–∞ —Å –ª–∏–¥–µ—Ä–æ–º ({competitive_analysis.get('competitive_gap', 0):.1f} –±–∞–ª–ª–æ–≤)")
            recommendations.append("–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ –ª—É—á—à–∏–µ –ø—Ä–∞–∫—Ç–∏–∫–∏ —Ç–æ–ø-–∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤")
        else:
            recommendations.append("–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: —É–ª—É—á—à–µ–Ω–∏–µ –±–∞–∑–æ–≤—ã—Ö –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π GEO-–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏")
            recommendations.append("–ò–∑—É—á–∏—Ç–µ –∏ –≤–Ω–µ–¥—Ä–∏—Ç–µ –ø–æ–¥—Ö–æ–¥—ã —Å–∞–π—Ç–æ–≤ –∏–∑ –≤–µ—Ä—Ö–Ω–µ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞")
        
        weaknesses = competitive_analysis.get('weaknesses', [])
        if any("—Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è" in weakness.lower() for weakness in weaknesses):
            recommendations.append("–£–≤–µ–ª–∏—á—å—Ç–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ clear answers –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
        if any("RAG" in weakness for weakness in weaknesses):
            recommendations.append("–û–ø—Ç–∏–º–∏–∑–∏—Ä—É–π—Ç–µ –∫–æ–Ω—Ç–µ–Ω—Ç –¥–ª—è Retrieval-Augmented Generation —Å–∏—Å—Ç–µ–º")
        if any("—Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è" in weakness.lower() for weakness in weaknesses):
            recommendations.append("–£–ª—É—á—à–∏—Ç–µ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫—É—é –ø–ª–æ—Ç–Ω–æ—Å—Ç—å —á–µ—Ä–µ–∑ —É–≥–ª—É–±–ª–µ–Ω–∏–µ —Ç–µ–º–∞—Ç–∏–∫–∏")
        
        recommendations.extend([
            "–†–µ–≥—É–ª—è—Ä–Ω–æ –º–æ–Ω–∏—Ç–æ—Ä—å—Ç–µ GEO-–ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤",
            "–ê–¥–∞–ø—Ç–∏—Ä—É–π—Ç–µ –∫–æ–Ω—Ç–µ–Ω—Ç-—Å—Ç—Ä–∞—Ç–µ–≥–∏—é –ø–æ–¥ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ —Ä–∞–∑–Ω—ã—Ö LLM",
            "–í–Ω–µ–¥—Ä—è–π—Ç–µ A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è GEO-—ç–ª–µ–º–µ–Ω—Ç–æ–≤"
        ])
        
        return recommendations

    def _get_deep_fallback_analysis(self, target_url: str, error_msg: str) -> Dict[str, Any]:
        """Fallback –¥–ª—è –≥–ª—É–±–æ–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
        return {
            'target_url': target_url,
            'competitors_analyzed': 0,
            'ranking': [],
            'competitive_analysis': {},
            'strengths_weaknesses': {},
            'strategic_recommendations': [
                "–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –ø–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤",
                "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å —Ü–µ–ª–µ–≤–æ–≥–æ URL",
                "–£–±–µ–¥–∏—Ç–µ—Å—å –≤ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ LLM API"
            ],
            'error': error_msg,
            'fallback_analysis': True
        }

    def clear_cache(self):
        """–û—á–∏—Å—Ç–∫–∞ –∫—ç—à–µ–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞"""
        self.competitor_cache.clear()
        self.comparative_analysis_cache.clear()
        self.analysis_cache.clear()
        logger.info("üßπ –ö—ç—à–∏ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ –æ—á–∏—â–µ–Ω—ã")
    
    def _get_fallback_analysis(self, content_data: Dict[str, Any]) -> Dict[str, Any]:
        """Fallback –∞–Ω–∞–ª–∏–∑ –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö –ø–æ–ª—É—á–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
        return {
            'overall_geo_score': 50,
            'citation_potential': 50,
            'semantic_density_score': 50,
            'clear_answer_quality': 50,
            'rag_optimization_score': 50,
            'category_scores': {
                'citation': 50,
                'semantic': 50,
                'structure': 50,
                'technical': 50,
                'rag': 50
            },
            'fallback_analysis': True,
            'error': '–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –ø–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–Ω—Ç–∞'
        }